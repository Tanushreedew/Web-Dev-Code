{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanushreedew/Web-Dev-Code/blob/main/lip_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQJ_BYgd3nW-",
        "outputId": "34e07a93-3f87-4654-f110-46549ea19c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPFyeyOC3heY"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GKayTa0ZhmG",
        "outputId": "57a33f06-2634-4d21-ab57-3829f42c7dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "hzxinGfNZzR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxvEjheD3oy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26339e8-b0b8-4972-de7e-e7d892e5e3d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor Frames: (75, 46, 140, 1)\n"
          ]
        }
      ],
      "source": [
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "predictor = dlib.shape_predictor('/content/drive/MyDrive/tanu_data/shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "def extract_frames_and_convert_to_tensor(eo_path):\n",
        "    frames = []\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(str(eo_path),cv2.CAP_ANY)\n",
        "\n",
        "    # Read and process each frame\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "      # hellop pranit yaan in the\n",
        "        # Convert frame to grayscale\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        expansion_factor = 1.3\n",
        "        image = frame_gray\n",
        "        faces = detector(frame_gray)\n",
        "\n",
        "\n",
        "        for face_index, face in enumerate(faces):\n",
        "            landmarks = predictor(image, face)\n",
        "\n",
        "            mouth_points = []\n",
        "            for n in range(48, 68):\n",
        "                x = landmarks.part(n).x\n",
        "                y = landmarks.part(n).y\n",
        "                mouth_points.append((x, y))\n",
        "\n",
        "\n",
        "            x_min = min([point[0] for point in mouth_points])\n",
        "            x_max = max([point[0] for point in mouth_points])\n",
        "            y_min = min([point[1] for point in mouth_points])\n",
        "            y_max = max([point[1] for point in mouth_points])\n",
        "\n",
        "            width = x_max - x_min\n",
        "            height = y_max - y_min\n",
        "            expansion_width = int(width * expansion_factor)\n",
        "            expansion_height = int(height * expansion_factor)\n",
        "            x_min_expanded = max(0, x_min - int((expansion_width - width) / 2))\n",
        "            y_min_expanded = max(0, y_min - int((expansion_height - height) / 2))\n",
        "            x_max_expanded = min(image.shape[1], x_max + int((expansion_width - width) / 2))\n",
        "            y_max_expanded = min(image.shape[0], y_max + int((expansion_height - height) / 2))\n",
        "\n",
        "\n",
        "            cropped_mouth = image[y_min_expanded:y_max_expanded, x_min_expanded:x_max_expanded]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Resize the frame to a consistent shape\n",
        "            resized_frame = cv2.resize(cropped_mouth, (140,46))\n",
        "            expanded_frame = np.expand_dims(resized_frame, axis=-1)\n",
        "            # reshaped_frame = np.expand_dims(frames, axis=-1)  # Add dimension for grayscale\n",
        "\n",
        "\n",
        "\n",
        "            # Convert the frame tensor to images (NumPy arrays)\n",
        "            # frame_images = tf.image.convert_image_dtype(resized_frame, tf.uint8).numpy()\n",
        "            frames.append(expanded_frame)\n",
        "\n",
        "    # Release the video capture\n",
        "    cap.release()\n",
        "\n",
        "    # Convert frames list to a TensorFlow tensor\n",
        "    tensor_frames = tf.convert_to_tensor(frames, dtype=tf.float32)\n",
        "    tensor_frames = tf.cast(frames, tf.float32)\n",
        "    # frame_images = tf.image.convert_image_dtype(frames, tf.uint8).numpy()\n",
        "    # mean =[]\n",
        "\n",
        "    return tensor_frames\n",
        "\n",
        "\n",
        "# Example usage\n",
        "video_path = \"/content/drive/MyDrive/test_data/test_video/bbwe2s.mpg\"\n",
        "tensor_frames = extract_frames_and_convert_to_tensor(video_path)\n",
        "# tensor_frames = np.expand_dims(tensor_frames, axis=-1)\n",
        "print(f\"Tensor Frames: {tensor_frames.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_video(path:str) -> List[float]:\n",
        "\n",
        "#     cap = cv2.VideoCapture(path)\n",
        "#     frames = []\n",
        "#     for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "#         ret, frame = cap.read()\n",
        "#         frame = tf.image.rgb_to_grayscale(frame)\n",
        "#         frames.append(frame[190:236,80:220,:])\n",
        "#     cap.release()\n",
        "\n",
        "#     mean = tf.math.reduce_mean(frames)\n",
        "#     std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "#     return tf.cast((frames - mean), tf.float32) / std"
      ],
      "metadata": {
        "id": "bcf1-V4Ueg3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQLmJ-aQ49e8",
        "outputId": "4163b8c5-ca43-4a76-87eb-c4a102455770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n",
            "tf.Tensor(\n",
            "[13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36\n",
            " 37 38  2 12  1  3  4  5  6  7  8  9 10 11  0], shape=(39,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(vocab)\n",
        "encoded_strings = encoder.transform(vocab)\n",
        "\n",
        "num_unique_strings = len(encoder.classes_)\n",
        "print(num_unique_strings)\n",
        "\n",
        "encoded_tensor = tf.constant(encoded_strings, dtype=tf.int32)\n",
        "print(encoded_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUOjuxBcKiGW",
        "outputId": "65643266-c1af-41db-eba7-65b4447d4396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_alignments(path:str) -> List[str]:\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens,' ',line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
      ],
      "metadata": {
        "id": "8P9W5f1oZFWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C002eaOc5ER9"
      },
      "outputs": [],
      "source": [
        "# def encoded_string(string):\n",
        "#     target_encoding = encoder.transform([string])[0]\n",
        "#     target_encoding = tf.constant(target_encoding, dtype=tf.int32)\n",
        "#     return target_encoding\n",
        "\n",
        "# def process_video_alignment(video_path):\n",
        "#     # Read the align file\n",
        "#     align_path =video_path\n",
        "\n",
        "#     with open(align_path, \"r\") as file:\n",
        "#         lines = file.readlines()\n",
        "\n",
        "#     # Extract the words and ignore time durations and \"sil\"\n",
        "#     transcription = []\n",
        "#     for line in lines[1:-1]:\n",
        "#         tokens = line.split()\n",
        "#         if tokens[2] != \"sil\":\n",
        "#             transcription.append(tokens[2] + \" \")\n",
        "\n",
        "#     # Join the tokens into a single string\n",
        "#     transcription_str = \"\".join(transcription).strip()\n",
        "#     tensor_transcription = tf.stack(\n",
        "#     [encoded_string(char) for char in transcription_str], axis=0\n",
        "#     )\n",
        "\n",
        "#     # Return the processed transcription string\n",
        "#     return tensor_transcription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDSWorQO5K21"
      },
      "outputs": [],
      "source": [
        "# def decode_tensor(tensor, encoder):\n",
        "#     decoded_chars = []\n",
        "#     for encoded_value in tensor:\n",
        "#         # encoded_value = encoded_value.numpy().astype(np.int64)\n",
        "#         decoded_chars.append(encoder.inverse_transform([encoded_value])[0])\n",
        "#     decoded_string = \"\".join(decoded_chars)\n",
        "#     return decoded_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DW0nFIe5O6S"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "def together(path: str):\n",
        "\n",
        "  path = bytes.decode(path.numpy())\n",
        "  split_value = []\n",
        "  tmp = ''\n",
        "  for c in path:\n",
        "    if c == '/':\n",
        "        split_value.append(tmp)\n",
        "        tmp = ''\n",
        "    else:\n",
        "        tmp += c\n",
        "  if tmp:\n",
        "    split_value.append(tmp)\n",
        "\n",
        "\n",
        "\n",
        "  split_value_2 = []\n",
        "  tmp = ''\n",
        "  for c in split_value[-1]:\n",
        "    if c == '.':\n",
        "        split_value_2.append(tmp)\n",
        "        tmp = ''\n",
        "    else:\n",
        "        tmp += c\n",
        "  if tmp:\n",
        "    split_value_2.append(tmp)\n",
        "\n",
        "  file_name = split_value_2[0]\n",
        "\n",
        "  # print(file_name)\n",
        "  alignment_path = os.path.join('/content/drive/MyDrive/test_data/','test_alignments',f'{file_name}.align')\n",
        "  alignment = load_alignments(alignment_path)\n",
        "\n",
        "  frames = extract_frames_and_convert_to_tensor(path)\n",
        "  return frames , alignment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_data(path: str):\n",
        "#     path = bytes.decode(path.numpy())\n",
        "#     file_name = path.split('/')[-1].split('.')[0]\n",
        "#     # File name splitting for windows\n",
        "#     #file_name = path.split('\\\\')[-1].split('.')[0]\n",
        "#     video_path = os.path.join('/content/drive/MyDrive/test_data','test_video',f'{file_name}.mpg')\n",
        "#     alignment_path = os.path.join('/content/drive/MyDrive/test_data','test_alignments',f'{file_name}.align')\n",
        "#     frames = extract_frames_and_convert_to_tensor(video_path)\n",
        "#     alignments = process_video_alignment(alignment_path)\n",
        "\n",
        "#     return frames, alignments"
      ],
      "metadata": {
        "id": "1GQNZqapbJpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1is31ys15pEL"
      },
      "outputs": [],
      "source": [
        "def mappable_function(path:str) ->List[str]:\n",
        "    result = tf.py_function(together, [path], (tf.float32, tf.int64))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_dwxUcY5fX3"
      },
      "outputs": [],
      "source": [
        "tf.data.experimental.enable_debug_mode()\n",
        "data = tf.data.Dataset.list_files('/content/drive/MyDrive/test_data/test_video/*.mpg')\n",
        "data = data.map(mappable_function)\n",
        "data = data.shuffle(1000, reshuffle_each_iteration=False)\n",
        "# Determine the maximum shape for padding\n",
        "max_frame_shape = tf.TensorShape([75, None, None,None])\n",
        "max_alignment_shape = tf.TensorShape([40])\n",
        "\n",
        "# Pad the dataset based on the maximum shape\n",
        "data = data.padded_batch(2, padded_shapes=(max_frame_shape, max_alignment_shape))\n",
        "\n",
        "data = data.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = data.take(50)\n",
        "val_ds = data.skip(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv__Ghqe5-1e",
        "outputId": "0de2e041-c746-4ad1-eaf5-4751a094b9c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkAqULZ_6FcS",
        "outputId": "b6b9c934-9ca4-439b-9427-2d6a7f788771"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s66P8MQg6ImQ",
        "outputId": "1f4aac8e-d8a2-405e-c4d0-ef47889d093e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "len(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPbYE0We6LP1"
      },
      "outputs": [],
      "source": [
        "frames, alignments = data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSP2m2B9hMCD",
        "outputId": "ab0aa3cd-cc7a-4711-c83e-9fc3f9bb9eda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75, 46, 140, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data.as_numpy_iterator().next()[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames_train, alignments_train = train_ds.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "2QjgLgGuKWF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames_val, alignments_val = val_ds.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "e6lxTTkZKWTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(256, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(75, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(41, kernel_initializer='he_normal', activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L-urtKOwKm-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJRCivc7q3QW",
        "outputId": "33549317-04a8-4570-aded-e02725578a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 75, 46, 140, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUVM8r0urEEp",
        "outputId": "23de0e9b-aae1-4809-aa4e-a0699f315a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 75, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "744qnt49xkYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = sample.next();"
      ],
      "metadata": {
        "id": "mFE6sZuXxqtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(val[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK8JUOY-xtVk",
        "outputId": "591de83a-50ee-455a-af2f-ccb6c2916489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 10s 10s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch < 30:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)"
      ],
      "metadata": {
        "id": "PR5QPZW1rLIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "vKQs-tM6rNRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProduceExample(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, dataset) -> None:\n",
        "        self.dataset = dataset.as_numpy_iterator()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
        "        data = self.dataset.next()\n",
        "        yhat = self.model.predict(data[0])\n",
        "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
        "        for x in range(len(yhat)):\n",
        "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
        "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
        "            print('~'*100)"
      ],
      "metadata": {
        "id": "QkMLfBpZrTji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"
      ],
      "metadata": {
        "id": "-p_FkMmWrX48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)"
      ],
      "metadata": {
        "id": "yz3UheyWrbt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_callback = LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "FMFKahC7rf4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_callback = ProduceExample(val_ds)"
      ],
      "metadata": {
        "id": "3orQ29l3rjUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3yeVlzYisFnT",
        "outputId": "917f95dc-2eab-456e-ead4-870046ceb149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Original: place blue with u four again\n",
            "Prediction: \n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original: lay blue with r four please\n",
            "Prediction: \n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "50/50 [==============================] - 867s 12s/step - loss: 130.2278 - val_loss: 114.1153 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "Original: set blue at l four soon\n",
            "Prediction:  \n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original: lay blue in d five again\n",
            "Prediction:  \n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "50/50 [==============================] - 610s 7s/step - loss: 109.2243 - val_loss: 99.9697 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Original: place blue at g eight again\n",
            "Prediction:  e e \n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original: place green at v three please\n",
            "Prediction:  e e \n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "50/50 [==============================] - 583s 6s/step - loss: 98.3450 - val_loss: 91.4014 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Original: set red with t four again\n",
            "Prediction: l e e e e\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original: place green in i one please\n",
            "Prediction: l e e e e\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "50/50 [==============================] - 580s 6s/step - loss: 87.1764 - val_loss: 78.9740 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "Original: lay blue with r five again\n",
            "Prediction: l e e e e\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original: lay green with k eight soon\n",
            "Prediction: l e e e e\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "50/50 [==============================] - 581s 6s/step - loss: 83.0730 - val_loss: 86.2142 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - ETA: 0s - loss: 79.3837"
          ]
        },
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d720992ee181>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-0bf626c3a466>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctc_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.unique(alignments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhKwZDOYGeVC",
        "outputId": "16c83d4a-6137-4d4e-8e84-18c3e2073e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1, 14, 15, 18, 19, 20, 22, 25, 27, 28, 29, 31, 32, 33, 34, 35,\n",
              "       38, 39], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data.classes_ = np.unique(alignments)"
      ],
      "metadata": {
        "id": "Tp2RCOobIm4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(data.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXREdUOIKLKo",
        "outputId": "94a69e6e-8493-47be-fbeb-7595e5a13bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1 14 15 18 19 20 22 25 27 28 29 31 32 33 34 35 38 39]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_weights('/content/drive/MyDrive/test_data/model_weights.h5')\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# # Define the loss function\n",
        "# loss_function = CategoricalCrossentropy()\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "# previous_weights_path = '/content/drive/MyDrive/test_data/model_weights.h5'\n",
        "# model.load_weights(previous_weights_path)\n",
        "# # Define the training data and labels\n",
        "# train_data = frames_train\n",
        "# train_labels = alignments_train\n",
        "\n",
        "# # Define the validation data and labels\n",
        "# val_data = frames_val\n",
        "# val_labels = alignments_val\n",
        "\n",
        "# # Convert labels to one-hot encoding if needed\n",
        "# train_labels_one_hot = tf.one_hot(train_labels, depth=40)\n",
        "# val_labels_one_hot = tf.one_hot(val_labels, depth=40)\n",
        "\n",
        "# class PrintAccuracyCallback(tf.keras.callbacks.Callback):\n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "#         print(f\"Accuracy: {logs['accuracy']}\")\n",
        "\n",
        "# # Train the model with validation data\n",
        "# model.fit(train_data, train_labels_one_hot, batch_size=32, epochs=10, validation_data=(val_data, val_labels_one_hot))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "51Hkvai6KtwZ",
        "outputId": "2793581e-5155-4493-e73f-5c756016f66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-149b7aaaee3f>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Train the model with validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   5557\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5558\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5559\u001b[0;31m     \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5561\u001b[0m     output, from_logits = _get_logits(\n",
            "\u001b[0;31mValueError\u001b[0m: Shapes (1, 40, 40) and (1, 40) are incompatible"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7qkQdZoipX3APQhtWF34D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}